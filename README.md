# NSU Machine Learning Course

Welcome to the **Machine Learning Course** at Novosibirsk State University. This repository includes all course materials: lecture notes, code examples, labs, assignments, and project guidelines.

## ðŸ“š Course Overview

This hands-on course covers essential machine learning techniques, including key algorithms like linear regression, decision trees, KNN, SVMs, and clustering. Through coding exercises and assignments, students will apply their skills to real-world data, culminating in a final project.

**Learning Outcomes:**

- Understand and implement core ML algorithms.
- Apply techniques to real-world data.
- Complete a final project showcasing practical ML skills.

## ðŸ—‚ Repository Contents

- **Lectures**: Slides and notes for each topic covered in the course.
- **Labs**: Jupyter notebooks and exercises for hands-on practice.
- **Assignments**: Weekly assignments for reinforcing the learned concepts.
- **Projects**: Guidelines and examples for the final project.
- **Resources**: Additional reading materials, research papers, and references.

## ðŸš€ Getting Started

To get started with the course materials:

1. **Clone the repository**:
   ```bash
   git clone https://github.com/luumsk/NSU_ML.git
   ```
2. **Install the required dependencies**:
   Ensure you have Python 3.x and necessary libraries installed:
   ```bash
   pip install -r requirements.txt
   ```

## ðŸ›  Tools and Libraries


- Python 3.x
- Jupyter Notebook
- NumPy, pandas, scikit-learn, matplotlib

Alternatively, you can upload this notebook to Google Colab or Kaggle for easier access to powerful computational resources and a collaborative environment.

## ðŸ“… Course Schedule


| Lecture | Topic                                                                | Description                                                                                                                       |
|---------|----------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------|
| 1       | **Introduction to Machine Learning**                                 | Definition, ML categories (supervised, unsupervised, reinforcement), applications in real life, and discussion on ML pipeline.    |
| 2       | **Data Preprocessing**                                               | Handling duplicated data, missing data, inconsistent data, and encoding categorical data.                                         |
| 3       | **Supervised Learning: Linear Regression**                           | Introduction to regression analysis, simple and multiple linear regression, evaluation metrics (MSE, RMSE, MAE, R2).              |
| 4       | **Supervised Learning: Non Linear Regression and Data Visualization**| Overview of nonlinear regression models and data visualization using libraries like Matplotlib and Seaborn.                       |
| 5       | **Supervised Learning: Logistic Regression and k-NN**                | Classification basics, logistic regression, decision boundary, and k-Nearest Neighbors (k-NN).                                    |
| 6       | **Tree-based Models: Decision Trees and Random Forests**             | Decision trees for classification and regression, overfitting and pruning, introduction to Random Forests.                        |
| 7       | **Practice Day**                                                     | Working with real Kaggle Competition dataset                                                                                      |
| 8       | **Support Vector Machines (SVM)**                                    | Theory behind SVM, kernel functions, hyperplane and margin concepts, applications in classification tasks.                        |
| 9       | **Ensemble Learning: Boosting Methods**                              | Bagging vs. boosting, AdaBoost, Gradient Boosting Machines (GBM), XGBoost, and introduction to CatBoost and LightGBM.             |
| 10      | **Unsupervised Learning: Clustering Techniques**                     | Introduction to clustering, k-Means, hierarchical clustering, evaluating clustering performance.                                  |
| 11      | **Hyperparameter Tuning and Model Optimization**                     | Practical approaches to hyperparameter tuning, using tools like GridSearchCV and Optuna.                                          |
| 12      | **Interpreting Machine Learning Models**                             | Importance of explainability, feature importance, SHAP, and LIME for understanding model predictions.                             |


## ðŸ“Š Grading Scheme

| Component         | Weight |
|-------------------|--------|
| **Assignments**   | 50%    |
| **Final Project** | 50%    |


## ðŸ“œ License

This repository is licensed under the [MIT License](LICENSE).

## ðŸ“§ Contact

For any questions or additional information, please contact [Khue Luu] at [khue.luu@g.nsu.ru].

---

Happy Learning! ðŸš€
